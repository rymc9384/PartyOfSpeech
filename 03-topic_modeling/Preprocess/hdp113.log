Reading in topictext_113Cong.csv...
Splitting corpus into 36760 training and 4085 testing documents...
Mapping tokens to numeric IDs...
Building word counts...
Counts produced for 5675 tokens...
Formatting text for the HDP model...
Saving training data to D:/cong_text/csvs/tokenized/topicmodeling/HDP/hdp113_train.txt...
Saving testing data to D:/cong_text/csvs/tokenized/topicmodeling/HDP/hdp113_test.txt...
DONE!
