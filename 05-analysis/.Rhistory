merged$ntoks[i] <- length(grams)
merged$allnouns[i] <- noun_ratio(grams = grams, propernouns = TRUE)
merged$nopropnouns[i] <- noun_ratio(grams = grams, propernouns = FALSE)
}
merged <- merged[merged$ntoks >= 25, ]
cat(paste0(rep("*", 15)))
cat("\t\tPERFORMING T-TESTS\t\t")
cat(paste0(rep("*", 15)))
# 3.1) All nouns:
r.allnn <- merged$allnouns[merged$party=="R"]
d.allnn <- merged$allnouns[merged$party != "R"]
allnn.ttest <- t.test(x = r.allnn, y = d.allnn, mu = 0.01, var.equal = FALSE)
# 3.2) No proper nouns:
r.noprop <- merged$nopropnouns[merged$party=="R"]
d.noprop <- merged$nopropnouns[merged$party != "R"]
noprop.ttest <- t.test(x = r.noprop, y = d.noprop, mu = 0.01, var.equal = FALSE)
cat("\n\nAll nouns t-test:")
print(allnn.ttest)
cat("\n\nNo proper nouns t-test:")
print(noprop.ttest)
sd(r.allnn)
sd(d.allnn)
sd(r.noprop)
sd(d.noprop)
rm(list=ls())
library(stringr)
library(optparse)
options(stringsAsFactors = F)
## Parse command line arguments:
option_list <- list(
make_option(c("-i", "--infile"), type="character", default="D:/cong_text/final_pos/topic_lemtag_merged_114.csv",
help="Merged topic lemma file [default=%default]", metavar="character"),
make_option(c("-lf", "--logfile"), type="character", default="./just_nouns.Rout",
help="logfile name [default= %default]", metavar="character")
)
opt_parser <- OptionParser(option_list=option_list)
opt <- parse_args(opt_parser)
get_tags <- function(text){
grams <- unlist(str_split(text, ' '))
grams <- gsub(pattern = ".*_", replacement = '', grams)
return(grams)
}
noun_ratio <- function(grams){
n1.count <- str_count(string = grams, pattern = "NNS?(?=$)")
n2.count <- str_count(string = grams, pattern = "NNPS?(?=$)")
n1.ratio <- sum(n1.count) / length(grams)
n2.ratio <- sum(n2.count) / length(grams)
return(c(n1.ratio, n2.ratio))
}
#########################
### 1) READ IN DATA
#########################
cat(paste0("\nReading in ", opt$infile, "...\n"))
merged <- read.csv(opt$infile)
#########################
### 2) COUNT NOUNS
#########################
cat("Counting nouns...\n")
merged$ntoks <- merged$nouns1 <- merged$nouns2 <- NA
for (i in 1:nrow(merged)){
grams <- get_tags(text = merged$lemma_text[i])
tmp <- noun_ratio(grams = grams)
merged$ntoks[i] <- length(grams)
merged$nouns1[i] <- tmp[1]
merged$nouns2[i] <- tmp[2]
}
merged <- merged[merged$ntoks >= 25,]
cat(paste0(rep("*", 15)))
cat("\t\tPERFORMING T-TESTS\t\t")
cat(paste0(rep("*", 15)))
r.nn1 <- merged$nouns1[merged$party=="R"]
d.nn1 <- merged$nouns1[merged$party != "R"]
r.nn2 <- merged$nouns2[merged$party=="R"]
d.nn2 <- merged$nouns2[merged$party != "R"]
## 3.1) Just nouns:
# 3.1a) null = 0%
nn01a.ttest <- t.test(x = r.nn1, y = d.nn1, mu = 0.00, var.equal = FALSE)
# 3.1b) null = 1%:
nn01b.ttest <- t.test(x = r.nn1, y = d.nn1, mu = 0.01, var.equal = FALSE)
## 3.2) Nouns & Proper nouns:
# 3.2a) null = 0%
nn02a.ttest <- t.test(x = r.nn2, y = d.nn2, mu = 0.00, var.equal = FALSE)
# 3.2b) null = 1%:
nn02b.ttest <- t.test(x = r.nn2, y = d.nn2, mu = 0.01, var.equal = FALSE)
## 4.1) Printing Just Nouns:
# 4.1a) null = 0%
cat("\n\nJust Nouns:\n\tNull = 0 t-test:")
print(nn01a.ttest)
# 4.1b) null = 0%
cat("\n\nJust Nouns:\n\tNull = 0.01 t-test:")
print(nn01b.ttest)
cat("\n\nNouns & Proper:\n\tNull = 0 t-test:")
print(nn02a.ttest)
# 4.1b) null = 0%
cat("\n\nNouns & Proper:\n\tNull = 0.01 t-test:")
print(nn02b.ttest)
?t.test
nn01.lm <- lm(nouns2 ~ ctr_ntoks + Repub, data = merged)
merged$Repub <- ifelse(merged$party == "R", 1, 0)
merged$ctr_ntoks <- log(merged$ntoks) - mean(log(merged$ntoks))
nn01.lm <- lm(nouns2 ~ ctr_ntoks + Repub, data = merged)
summary(nn01.lm)
nn02.lm <- lm(nouns2 ~ ctr_ntoks * Repub, data = merged)
summary(nn02.lm)
plot(merged$ntoks, merged$nouns2)
plot(merged$ctr_ntoks, merged$nouns2)
nn02.lm <- lm(nouns2 ~ ctr_ntoks + I(ctr_ntoks^2) Repub, data = merged)
nn02.lm <- lm(nouns2 ~ ctr_ntoks + I(ctr_ntoks^2) + Repub, data = merged)
summary(nn02.lm)
nn02.lm <- lm(nouns2 ~ ctr_ntoks + I(ctr_ntoks^2) + I(ctr_ntoks^3) +Repub, data = merged)
summary(nn02.lm)
nn01.lm <- lm(nouns1 ~ ctr_ntoks + Repub, data = merged)
nn02.lm <- lm(nouns2 ~ ctr_ntoks + Repub, data = merged)
summary(nn01.lm)
plot(merged$ctr_ntoks, merged$nouns1)
plot(merged$ctr_ntoks, merged$nouns1, bg = factor(merged$Repub))
plot(merged$ctr_ntoks, merged$nouns1, pch=21, bg = factor(merged$Repub))
by(merged$nouns1, merged$Repub, summary)
nn02.lm <- lm(nouns2 ~ ctr_ntoks * Repub, data = merged)
nn01.lm <- lm(nouns1 ~ ctr_ntoks * Repub, data = merged)
summary(nn01.lm)
summary(nn02.lm)
summary(merged$ctr_ntoks)
merged$ctr_ntoks <- (log(merged$ntoks) - mean(log(merged$ntoks))) / sd(log(merged$ntoks))
plot(density(merged$ctr_ntoks))
summary(merged$ctr_ntoks)
# 4.2a) just nouns
nn01.lm <- lm(nouns1 ~ ctr_ntoks + Repub, data = merged)
# 4.2b) nouns & proper
nn02.lm <- lm(nouns2 ~ ctr_ntoks + Repub, data = merged)
summary(nn01.lm)
summary(nn02.lm)
plot(merged$ctr_ntoks, merged$nouns1, pch=21, bg = factor(merged$Repub))
plot(merged$ctr_ntoks, merged$nouns2, pch=21, bg = factor(merged$Repub))
quantile(x = merged$ctr_ntoks, probs = c(0.35, 0.66, 0.95))
quantile(x = merged$ctr_ntoks, probs = c(0.025, 0.20, 0.80 , 0.975))
sd(merged$ctr_ntoks)
nn01.lm <- lm(nouns1 ~ ctr_ntoks * Repub, data = merged)
nn02.lm <- lm(nouns2 ~ ctr_ntoks * Repub, data = merged)
summary(nn01.lm)
summary(nn02.lm)
print(nn02a.ttest)
print(nn02b.ttest)
print(nn01a.ttest)
get_tags <- function(text){
grams <- unlist(str_split(text, ' '))
grams <- gsub(pattern = ".*_", replacement = '', grams)
return(grams)
}
noun_ratio <- function(grams){
n1.count <- str_count(string = grams, pattern = "NNS?(?=$)")
n2.count <- str_count(string = grams, pattern = "(NNS?|NNPS?)(?=$)")
n1.ratio <- sum(n1.count) / length(grams)
n2.ratio <- sum(n2.count) / length(grams)
return(c(n1.ratio, n2.ratio))
}
#########################
### 1) READ IN DATA
#########################
cat(paste0("\nReading in ", opt$infile, "...\n"))
merged <- read.csv(opt$infile)
#########################
### 2) COUNT NOUNS
#########################
cat("Counting nouns...\n")
merged$ntoks <- merged$nouns1 <- merged$nouns2 <- NA
for (i in 1:nrow(merged)){
grams <- get_tags(text = merged$lemma_text[i])
tmp <- noun_ratio(grams = grams)
merged$ntoks[i] <- length(grams)
merged$nouns1[i] <- tmp[1]
merged$nouns2[i] <- tmp[2]
}
## Drop releases w/ fewer than 25 tokens:
merged <- merged[merged$ntoks >= 25,]
cat(paste0(rep("*", 15)))
cat("\t\tPERFORMING T-TESTS\t\t")
cat(paste0(rep("*", 15)))
r.nn1 <- merged$nouns1[merged$party=="R"]
d.nn1 <- merged$nouns1[merged$party != "R"]
r.nn2 <- merged$nouns2[merged$party=="R"]
d.nn2 <- merged$nouns2[merged$party != "R"]
## 3.1) Just nouns:
# 3.1a) null = 0%
nn01a.ttest <- t.test(x = r.nn1, y = d.nn1, mu = 0.00, var.equal = FALSE)
# 3.1b) null = 1%:
nn01b.ttest <- t.test(x = r.nn1, y = d.nn1, mu = 0.01, var.equal = FALSE)
## 3.2) Nouns & Proper nouns:
# 3.2a) null = 0%
nn02a.ttest <- t.test(x = r.nn2, y = d.nn2, mu = 0.00, var.equal = FALSE)
# 3.2b) null = 1%:
nn02b.ttest <- t.test(x = r.nn2, y = d.nn2, mu = 0.01, var.equal = FALSE)
#########################
### 4) REGRESSION
#########################
## 4.1) Clean control variables:
merged$Repub <- ifelse(merged$party == "R", 1, 0)
merged$ctr_ntoks <- (log(merged$ntoks) - mean(log(merged$ntoks))) / sd(log(merged$ntoks))
## 4.2) Modeling
# 4.2a) just nouns
nn01a.lm <- lm(nouns1 ~ ctr_ntoks + Repub, data = merged)
nn01b.lm <- lm(nouns1 ~ ctr_ntoks * Repub, data = merged)
# 4.2b) nouns & proper
nn02a.lm <- lm(nouns2 ~ ctr_ntoks + Repub, data = merged)
nn02b.lm <- lm(nouns2 ~ ctr_ntoks * Repub, data = merged)
cat("\n\nJust Nouns:\n\tNull = 0 t-test:")
print(nn01a.ttest)
# 4.1b) null = 0%
cat("\n\nJust Nouns:\n\tNull = 0.01 t-test:")
print(nn01b.ttest)
## 4.2) Printing Nouns & Proper:
# 4.2a) null = 0%
cat("\n\nNouns & Proper:\n\tNull = 0 t-test:")
print(nn02a.ttest)
# 4.2b) null = 0%
cat("\n\nNouns & Proper:\n\tNull = 0.01 t-test:")
print(nn02b.ttest)
summary(nn02.lm)
summary(nn02a.lm)
summary(nn02b.lm)
cat("\n\t\tT-tests")
cat("\n\t*****T-tests******")
print(nn01b.lm)
print(summary(nn02b.lm))
print(summary(nn02a.lm))
print(summary(nn01b.lm))
print(summary(nn01a.lm))
merged$nouns1 <- merged$nouns1 * 100
merged$nouns2 <- merged$nouns2 * 100
# 4.1b) binary party & scale word counts
merged$Repub <- ifelse(merged$party == "R", 1, 0)
merged$ctr_ntoks <- (log(merged$ntoks) - mean(log(merged$ntoks))) / sd(log(merged$ntoks))
## 4.2) Modeling
# 4.2a) just nouns
nn01a.lm <- lm(nouns1 ~ ctr_ntoks + Repub, data = merged)
nn01b.lm <- lm(nouns1 ~ ctr_ntoks * Repub, data = merged)
# 4.2b) nouns & proper
nn02a.lm <- lm(nouns2 ~ ctr_ntoks + Repub, data = merged)
nn02b.lm <- lm(nouns2 ~ ctr_ntoks * Repub, data = merged)
cat("\n\t******OLS MODELS******")
## 6.1) Printing Just Nouns:
# 6.1a) null = 0%
cat("\n\nJust Nouns:\n\tAdditive:")
print(summary(nn01a.lm))
# 6.1b) null = 0%
cat("\n\nJust Nouns:\n\tInteractive:")
print(summary(nn01b.lm))
## 6.2) Printing Nouns & Proper:
# 6.2a) null = 0%
cat("\n\nNouns & Proper:\n\tAdditive:")
print(summary(nn02a.lm))
# 6.2b) null = 0%
cat("\n\nNouns & Proper:\n\tInteractive:")
print(summary(nn02b.lm))
cat("\n\t******OLS MODELS******")
cat("\n\t*** % Points ***")
cat("\n\t   *** % Points ***")
cat("\n\t******OLS MODELS******")
cat("\n\t   *** % Points ***")
cat("\n\t******OLS MODELS******")
cat("\n\t     Scaled to %")
cat("\n\t****** OLS MODELS ******")
cat("\n\t    * Scaled to % *")
rm(list = ls())
set.seed(11243)
#########################
### 0) LOAD + PROCESS SENATE RESULTS
#########################
# read in data
load("D:/cong_text/final_pos/analysis/noun_ratios.RData")
# scale diff in means to be percentage points
allnn.mu <- (allnn.ttest$estimate[1] - allnn.ttest$estimate[2]) * 100
noprop.mu <- (noprop.ttest$estimate[1] - noprop.ttest$estimate[2]) * 100
#########################
### 1) CONSTRUCT CICHOCKA ET AL. RESULTS
#########################
## 1.a) Parameters from Cichocka et al. (2016, 809)
R.n <- 45
R.mean <- 0.26
R.sd <- 0.02
D.n <- 56
D.mean <- 0.25
D.sd <- 0.01
## 1.b) Simulate confidence intervals for t-test:
# number of sims and var holding results
B <- 1001
diffs <- NA
# Simulate `B` times
for (i in 1:B){
R <- rnorm(R.n, R.mean, R.sd)
D <- rnorm(D.n, D.mean, D.sd)
diffs[i] <- mean(R) - mean(D)
}
## 1.c) Process simulation results:
# Sort diffs in means, then get vals from 0.025, 0.5, and 0.975 quantiles;
# also, scale them to percentage points.
diffs <- sort(diffs)
Cich.ci <- diffs[c(14,988)] * 100
Cich.mu <- median(diffs) * 100
par(mar=c(5,5,2,2))
# base plot
plot(x = 0, y = 0, type = "n", xlim = c(0, 2), ylim = c(-1, 2), axes = F,
ylab = "Percentage Points Difference", xlab = "", cex.lab = 1.5,
panel.first = grid(lwd=2.5))
axis(side = 1, at = c(0.5, 1, 1.5), cex.axis = 1.5,
labels = c("Senate\nIncl. Proper Nouns", "Cichocka et al.\n(2016)", "Senate\nNo Proper Nouns"),
lwd = 0, line = 1)
axis(side = 2, at = seq(-2,2,by=0.5), cex.axis = 1.5)
lines(x = c(0, 2), y = c(0, 0))
# diff in means as points
points(x = c(0.5, 1, 1.5), y = c(allnn.mu, Cich.mu, noprop.mu), pch = c(21, 23, 21),
bg = c("steelblue", "orangered2", "steelblue"), cex = 1.5, col = NA)
# confidence intervals
lines(x = c(0.5, 0.5), y = allnn.ttest$conf.int * 100, lwd = 3, col = "steelblue")
lines(x = c(1.0, 1.0), y = Cich.ci, lwd = 3, col = "orangered2")
lines(x = c(1.5, 1.5), y = noprop.ttest$conf.int * 100, lwd = 3, col = "steelblue")
pdf(file = "D:/Dropbox/Dissertation/02-pos_senate/02-writing/figures/01-noun_ratio_comparison.pdf",
width = 10.5, height = 7, encoding = "WinAnsi.enc")
# adjust margins
par(mar=c(5,5,2,2))
# base plot
plot(x = 0, y = 0, type = "n", xlim = c(0, 2), ylim = c(-1, 2), axes = F,
ylab = "Percentage Points Difference", xlab = "", cex.lab = 1.5,
panel.first = grid(lwd=2.5))
axis(side = 1, at = c(0.5, 1, 1.5), cex.axis = 1.5,
labels = c("Senate\nIncl. Proper Nouns", "Cichocka et al.\n(2016)", "Senate\nNo Proper Nouns"),
lwd = 0, line = 1)
axis(side = 2, at = seq(-2,2,by=0.5), cex.axis = 1.5)
lines(x = c(0, 2), y = c(0, 0))
# diff in means as points
points(x = c(0.5, 1, 1.5), y = c(allnn.mu, Cich.mu, noprop.mu), pch = c(21, 23, 21),
bg = c("steelblue", "orangered2", "steelblue"), cex = 1.5, col = NA)
# confidence intervals
lines(x = c(0.5, 0.5), y = allnn.ttest$conf.int * 100, lwd = 3, col = "steelblue")
lines(x = c(1.0, 1.0), y = Cich.ci, lwd = 3, col = "orangered2")
lines(x = c(1.5, 1.5), y = noprop.ttest$conf.int * 100, lwd = 3, col = "steelblue")
dev.off()
rm(list=ls())
options(stringsAsFactors = F)
#########################
### 0) FUNCTIONS + CONSTANTS
#########################
## 0.a) Constants
# intertopic
R.ZETA1 <- 4.42
D.ZETA1 <- -4.42
# intratopic
R.ZETA2 <- 3.29
D.ZETA2 <- -3.29
## 0.b) Topic significance
topicsig <- function(zetas, cutR=R.ZETA2, cutD=D.ZETA2){
t <- length(zetas)
r <- which(zetas >= cutR)
d <- which(zetas <= cutD)
n <- which( 1:t %in% r == F & 1:t %in% d == F)
zetas[r] <- "GOP"
zetas[d] <- "DEM"
zetas[n] <- "---"
return(zetas)
}
#########################
### 1) READ IN DATA
#########################
# pronouns
prp.df <- read.csv("D:/cong_text/final_pos/analysis/zetas_prpnum_feats.csv")
# verbs
vb.df <- read.csv("D:/cong_text/final_pos/analysis/zetas_vrbtense_feats.csv")
# nouns
nn.df <- read.csv("D:/cong_text/final_pos/analysis/zetas_nounnum_feats.csv")
# merge
df <- cbind(prp.df, vb.df[,-1], nn.df[,-1])
# subset inter-topic
df.inter <- df[1, ]
df <- df[-1, ]
# remove constituent frames
rm('prp.df', 'vb.df', 'nn.df')
#########################
### 2) INTERTOPIC
#########################
tab.inter <- df.inter
tab.inter[1,2:7] <- topicsig(zetas = tab.inter[1,2:7], cutR = R.ZETA1, cutD = D.ZETA1)
#########################
### 3) INTRATOPIC
#########################
tab.intra <- df
for (i in 2:7){
tab.intra[,i] <- topicsig(zetas = tab.intra[,i])
}
#########################
### 3) SUMMARY BY COL
#########################
# get number of topics sig in predicted direction for each column
n.sig <- NA
for (i in 2:7){
if (i %% 2 == 0){
n.sig[i] <- sum(tab.intra[,i] == "GOP")
} else{
n.sig[i] <- sum(tab.intra[,i] == "DEM")
}
}
tab.full <- rbind(tab.inter, tab.intra, n.sig)
View(tab.full)
###########################################################################
rm(list=ls())
library(stringr)
library(optparse)
options(stringsAsFactors = F)
## Parse command line arguments:
option_list <- list(
make_option(c("-i", "--infile"), type="character", default="D:/cong_text/final_pos/topic_lemtag_merged_114.csv",
help="Merged topic lemma file [default=%default]", metavar="character"),
make_option(c("-lf", "--logfile"), type="character", default="./just_nouns.Rout",
help="logfile name [default= %default]", metavar="character")
)
opt_parser <- OptionParser(option_list=option_list)
opt <- parse_args(opt_parser)
library(multilevel)
install.packages("multilevel")
library(multilevel)
set.seed(1124)
get_tags <- function(text){
grams <- unlist(str_split(text, ' '))
grams <- gsub(pattern = ".*_", replacement = '', grams)
return(grams)
}
noun_ratio <- function(grams){
n1.count <- str_count(string = grams, pattern = "NNS?(?=$)")
n2.count <- str_count(string = grams, pattern = "(NNS?|NNPS?)(?=$)")
n1.ratio <- sum(n1.count) / length(grams)
n2.ratio <- sum(n2.count) / length(grams)
return(c(n1.ratio, n2.ratio))
}
#########################
### 1) READ IN DATA
#########################
cat(paste0("\nReading in ", opt$infile, "...\n"))
merged <- read.csv(opt$infile)
#########################
### 2) COUNT NOUNS
#########################
cat("Counting nouns...\n")
merged$ntoks <- merged$nouns1 <- merged$nouns2 <- NA
for (i in 1:nrow(merged)){
grams <- get_tags(text = merged$lemma_text[i])
tmp <- noun_ratio(grams = grams)
merged$ntoks[i] <- length(grams)
merged$nouns1[i] <- tmp[1]
merged$nouns2[i] <- tmp[2]
}
## Drop releases w/ fewer than 25 tokens:
merged <- merged[merged$ntoks >= 25,]
null.mod <- lme(fixed = nouns2 ~ 1, random = ~1|sen, data = merged)
null.mod
VarCorr(null.mod)
0.0002679925 / (0.0002679925 + 0.0021051598)
nul.gls <- gls(model = nouns2 ~ 1, data = merged)
logLik(nul.gls) * -2
logLik(null.mod) * -2
anova(nul.gls, null.mod)
mod1 <- lme(fixed = nouns2 ~ I(party=="R"), random=~1|sen, data = merged)
summary(mod1)
library(lattice)
xyplot(nouns2~I(party=="R")|as.factor(sen), data=merged, type=c("p","g","r"),col="dark blu
e",col.line="black",
xlab="party", ylab="Noun Proportion")
mod1 <- lme(fixed = nouns2 ~ I(party=="R") + ntoks, random=~1|sen, data = merged)
summary(mod1)
xyplot(nouns2~ntoks|as.factor(sen), data=merged, type=c("p","g","r"),col="dark blu
e",col.line="black",
xlab="Tokens", ylab="Noun Proportion")
xyplot(nouns2~ntoks|as.factor(sen), data=merged[1:5000,], type=c("p","g","r"),col="blu
e",col.line="black",
xlab="Tokens", ylab="Noun Proportion")
xyplot(nouns2~ntoks|as.factor(sen), data=merged[1:5000,], type=c("p","g","r"),col="dark blue",col.line="black",
xlab="Tokens", ylab="Noun Proportion")
xyplot(nouns2~ntoks|as.factor(sen), data=merged, type=c("p","g","r"),col="dark blue",col.line="black",
xlab="Tokens", ylab="Noun Proportion")
xyplot(nouns2~ntoks|as.factor(sen), data=merged[1:10000,], type=c("p","g","r"),col="dark blue",col.line="black",
xlab="Tokens", ylab="Noun Proportion")
xyplot(nouns2~ntoks|as.factor(sen), data=merged[1:7000,], type=c("p","g","r"),col="dark blue",col.line="black",
xlab="Tokens", ylab="Noun Proportion")
xyplot(nouns2~ntoks|as.factor(sen), data=merged[7001:15000,], type=c("p","g","r"),col="dark blue",col.line="black",
xlab="Tokens", ylab="Noun Proportion")
xyplot(nouns2~ntoks|as.factor(sen), data=merged[7001:20000,], type=c("p","g","r"),col="dark blue",col.line="black",
xlab="Tokens", ylab="Noun Proportion")
mod2 <- lme(fixed = nouns2 ~ I(party=="R") + ntoks, random=~ntoks|sen, data = merged)
summary(mod2)
mod2a <- update(mod2, random=~1|sen)
anova(mod2a, mod2)
mod2 <- lme(fixed = nouns2 ~ I(party=="R") + ntoks, random=~topic|sen, data = merged)
summary(mod2)
mod2 <- lme(fixed = nouns2 ~ I(party=="R") + ntoks + factor(topic), random=~topic|sen, data = merged)
summary(mod2)
library(lme4)
mod3 <- lmer(nouns2 ~ 1  I(party=="R") + ntoks +
mod3 <- lmer(nouns2 ~ 1 + I(party=="R") + ntoks + (1|sen) + (1|topic), data = merged)
summary(mod3)
ranef(mod4)
ranef(mod3)
mod3 <- lmer(nouns2 ~ 1 + I(party=="R") + ntoks + (ntoks|sen) + (ntoks|topic), data = merged)
mod3 <- lmer(nouns2 ~ 1 + I(party=="R") + ntoks + (ntoks|sen) + (1|topic), data = merged)
mod3 <- lmer(nouns2 ~ 1 + I(party=="R") + ntoks + (~ntoks|sen) + (1|topic), data = merged)
mod2
mod2 <- lme(fixed = nouns2 ~ I(party=="R") + ntoks, random=~topic|sen/as.factor(topic), data = merged)
mod2 <- lme(fixed = nouns2 ~ I(party=="R") + ntoks, random=~ntoks|sen/as.factor(topic), data = merged)
mod2 <- lme(fixed = nouns2 ~ I(party=="R") + log(ntoks), random=~1|sen/as.factor(topic), data = merged)
mod2 <- lme(fixed = nouns2 ~ I(party=="R") + log(ntoks), random=~1|sen, data = merged)
summary(mod2)
mod2 <- lme(fixed = nouns2 ~ I(party=="R") + log(ntoks), random=log(ntoks)|sen, data = merged)
mod2 <- lme(fixed = nouns2 ~ I(party=="R") + log(ntoks), random=~log(ntoks)|sen, data = merged)
mod2 <- lme(fixed = nouns2 ~ I(party=="R"), random=~log(ntoks)|sen, data = merged)
mod2 <- lme(fixed = nouns2 ~ I(party=="R") + log(ntoks), random=~1|sen, data = merged)
